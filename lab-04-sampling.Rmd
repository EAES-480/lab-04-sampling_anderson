---
title: "Lab 04 — Sampling from Time Series"
author: "EAES 480 — Modern Statistics in Earth & Environmental Science"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  html_document:
    theme: cosmo
    highlight: tango
    toc: true
    toc_depth: 3
    toc_float: true
    code_folding: hide
    df_print: paged
editor_options:
  chunk_output_type: inline
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(janitor)

knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE
)
```

# Overview

## What is AmeriFlux?

**AmeriFlux** is a network of **eddy covariance** flux-tower sites that measure exchanges of **carbon (CO₂), water, and energy** between ecosystems and the atmosphere, with standardized data products shared for research and education.

In this lab, you will use a simplified AmeriFlux-style dataset from the **US-AMS site at Argonne National Laboratory (near Chicago)**. The measurements are at **30-minute resolution** over **2023**, and show strong **seasonality** and **day–night cycles**.

**Key idea for this lab:** treat the full 2023 time series as the **population**, then practice sampling strategies to estimate population parameters.

References for context:
- AmeriFlux overview: https://ameriflux.lbl.gov/about/about-ameriflux/
- US-AMS site page: https://ameriflux.lbl.gov/sites/siteinfo/US-AMS

---

# Learning goals

By the end of this lab, you should be able to:

- Define a **population** and a **sample** for an EAES time-series dataset
- Compute population **parameters** (mean, SD) and compare to sample **estimates**
- Visualize distributions and identify **latent grouping variables** (month, day/night)
- Implement **simple random sampling** and **stratified sampling**
- Use `set.seed()` to make sampling reproducible

---

# Data

## Load and inspect

```{r load_data, echo=TRUE, eval=T}
df <- read_csv("data/us-ams-simple.csv") %>%
  clean_names() %>% filter(year_local == 2023)

glimpse(df)
```

**CHECK:** You should see columns like `year_local`, `doy`, `daytime`, and flux/biomet variables (e.g., `gpp`, `fc`, `le`, `ta`).

---

## Create a date and month column from DOY

This dataset uses **Year + Day-of-Year (DOY)**. Month must be derived from a calendar date.

```{r derive_time, echo=TRUE, eval=T}
df <- df %>%
  mutate(
    # TODO: create a Date column from year_local and doy
    # HINT: Jan 1 is DOY = 1, so use (doy - 1) with origin = "YYYY-01-01"
    date = as.Date(doy - 1, origin = paste0(2023, "-01-01")),

    # TODO: create a month column (numeric 1–12 or labeled months)
    month = month(date, label = TRUE, abbr = TRUE),

    # TODO: make a day/night label using daytime (0/1)
    day_night = if_else(daytime == 1, "Day", "Night")
  )

count(df, month)
count(df, day_night)
```

---

# Choose a response variable

You will analyze **one response variable** throughout the lab. This could be a CO₂ flux metric or a meteorological variable.

Examples you can choose from (depending on what you see in the dataset):
- CO₂ / carbon: `gpp`, `reco`, `fc`
- Energy: `le`
- Meteorology: `ta`, `ts`, `swc`

```{r choose_response, echo=TRUE, eval=T}
# TODO: choose ONE response variable (a column name as a string)
response_var <- "ta"   # replace "gpp" with your choice, e.g. "fc" or "le" or "ta"

# CHECK: print a quick summary
df %>% summarise(
  n = n(),
  n_missing = sum(is.na(ta)),
  mean = mean(ta, na.rm = TRUE),
  sd = sd(ta, na.rm = TRUE)
)
```

**Prompt (2–3 sentences):** Why did you choose this response variable? What do you expect its seasonality/day–night pattern to be?

I chose this response variable because it should have a clear pattern between seasons and time of day. I expect during JJA and morning times it will be at its highest, while during DJF and evening times it should be at its lowest. 

---

# Section 1 — Data dictionary (conceptual)

Students will populate the data dictionary using:
https://ameriflux.lbl.gov/data/aboutdata/data-variables/

Fill in at least **5 variables** from this dataset:

| Variable | Units | Description | Expected sign/seasonality? |
|----------|-------|-------------|----------------------------|
|  ta   | deg C |air temperature|  high in summer         |
| le  |  W m-2  | latent heat |              |
| gpp | µmolCO2 m-2 s-1|gross primary productivity| high in spring/summer  |
| swc |   %  | soil water content | low in summer |
| ts  |  deg C |soil temperature |     high in summer      |

---

# Section 2 — Visualizing the population

Remember: for this lab, the **population** is the entire 2023 half-hourly time series.

## 2.1 Time series view

```{r plot_time_series, echo=TRUE, eval=T}
# GOAL: Visualize seasonality over the year.
# TODO: pick a y aesthetic using response_var.

df %>%
  ggplot(aes(x = date, y = ta)) +
  geom_line(alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(
    x = NULL,
    y = response_var,
    title = "Population time series (2023)"
  )
```

**Prompt (2–3 sentences):** What major patterns do you see? (Seasonal cycle? Daily cycle? Outliers?)

It seems to be dependent most on time of year. Towards the middle of the response, which would be the summer months, the data increases. 

---

## 2.2 Population distribution (histogram + density)

```{r pop_distribution, echo=TRUE, eval=T}
# GOAL: See the overall distribution of the population.
# TODO: choose an appropriate number of bins (start with ~50).

ggplot(df, aes(x = ta)) +
  geom_histogram(bins = 50, alpha = 0.7) +
  theme_classic(base_size = 18) +
  labs(x = response_var, y = "Count", title = "Population distribution (histogram)")

ggplot(df, aes(x = ta)) +
  geom_density(alpha = 0.7) +
  theme_classic(base_size = 18) +
  labs(x = response_var, y = "Density", title = "Population distribution (density)")
```

**Prompt:** Describe shape (skew, modality), center, and spread.

The distribution is bimodal, mostly symmetrical, centered around 10, and has a spread from -15-35

---

## 2.3 Do latent groups explain variability? (month, day/night)

### By month

```{r pop_by_month, echo=TRUE, eval=T}
# TODO: make month appear in a sensible order (it already is an ordered factor if label=TRUE)
df %>%
  ggplot(aes(x = month, y = ta)) +
  geom_boxplot(outlier.alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(x = NULL, y = response_var, title = "Population by month")
```

### By day/night

```{r pop_by_daynight, echo=TRUE, eval=T}
df %>%
  ggplot(aes(x = day_night, y = ta)) +
  geom_boxplot(outlier.alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(x = NULL, y = response_var, title = "Population by day vs night")
```

**Prompt (3–4 sentences):** Which grouping variable (month or day/night) seems to explain more variability in your response? Why?

It appears the month experiences more variability. Although the day/night shows some differences, it is much more stark in the month plot. The increase in the summer season (JJA) would cause the most variability in the response.

---

# Section 3 — Population parameters (truth)

Compute the population mean and SD for your chosen response variable.

```{r population_params, echo=TRUE, eval=T}
pop_mean <- mean(df$ta, na.rm = TRUE)
pop_sd   <- sd(df$ta, na.rm = TRUE)

tibble(
  response_var = response_var,
  population_mean = pop_mean,
  population_sd = pop_sd
)
```

---

# Section 4 — Simple random sampling (SRS)

## 4.1 One random sample

```{r one_sample, echo=TRUE, eval=T}
set.seed(480)

# TODO: choose a sample size (e.g., 200, 500, 1000)
n_samp <- 200

samp <- df %>%
  slice_sample(n = n_samp)

samp_mean <- mean(samp$ta, na.rm = TRUE)
samp_sd   <- sd(samp$ta, na.rm = TRUE)

tibble(
  n_samp = n_samp,
  sample_mean = samp_mean,
  sample_sd = samp_sd,
  pop_mean = pop_mean,
  pop_sd = pop_sd
)
```

**Prompt (2–3 sentences):** How close is your one-sample estimate to the population mean/SD? Is the difference surprising?

It is extremely similar, off by ~ 0.40. There is going to be some variability, so it isn't that surprising. 

---

## 4.2 Sampling variability: many samples → many means

```{r sampling_distribution, echo=TRUE, eval=T}
set.seed(480)

reps <- 500  # TODO: choose number of replicates (e.g., 500 or 1000)

means <- replicate(
  reps,
  df %>%
    slice_sample(n = n_samp) %>%
    summarise(m = mean(ta, na.rm = TRUE)) %>%
    pull(m)
)

ggplot(tibble(mean_est = means), aes(mean_est)) +
  geom_histogram(bins = 40, alpha = 0.8) +
  geom_vline(xintercept = pop_mean, linetype = "dashed", linewidth = 1.1) +
  theme_classic(base_size = 18) +
  labs(
    x = paste0("Sample mean of ", response_var),
    y = "Count",
    title = "Sampling distribution of the mean (SRS)",
    subtitle = "Dashed line = population mean"
  )
```

**Prompt (2–3 sentences):** Is the sampling distribution centered on the population mean? What happens if you increase `n_samp`?

It's closely centered on the population mean. If I were to increase `n_samp` the variability would decrease and the distribution would appear more normal.

---

# Section 5 — Stratified sampling

Here you’ll test whether stratification helps when the population has structure.

## 5.1 Stratify by month

```{r strat_by_month, echo=TRUE, eval=T}
set.seed(480)

# GOAL: sample within each month to ensure seasonal representation.
# TODO: choose n_per_month so total sample size is reasonable (e.g., 12 * 20 = 240)
n_per_month <- 15

samp_strat <- df %>%
  group_by(month) %>%
  slice_sample(n = n_per_month) %>%
  ungroup()

strat_mean <- mean(samp_strat$ta, na.rm = TRUE)
strat_sd   <- sd(samp_strat$ta, na.rm = TRUE)

tibble(
  n_per_month = n_per_month,
  total_n = nrow(samp_strat),
  strat_mean = strat_mean,
  strat_sd = strat_sd,
  pop_mean = pop_mean,
  pop_sd = pop_sd
)
```

---

## 5.2 Compare strategies (SRS vs stratified)

```{r compare_sampling, echo=TRUE, eval=T}
tibble(
  strategy = c("Population", "SRS", "Stratified by month"),
  mean = c(pop_mean, samp_mean, strat_mean),
  sd   = c(pop_sd,   samp_sd,   strat_sd)
)
```

**Prompt (3–4 sentences):** Which strategy better approximated the population mean and SD for your response variable? Why might stratification help (or not) here?

Stratified by month is the better approximation. Stratification helps when the variable being stratified is related to the response variable. By dividing the population into groups, we can make sure the sample is representative of the population. This would reduce sampling error. 

---

# Section 6 — Conceptual reflection

Answer in **4–6 sentences**:

- Why does seasonality matter for sampling?
- What happens if sampling ignores latent grouping variables?
- In EAES field studies, when is stratification essential?
- What is one trade-off of stratified sampling?

Seasonality is critical in sampling because environmental characteristics and patterns shift throughout the year. This means a sample taken in one season may not represent the population in another. 
Ignoring latent grouping can result in misleading and unreliable conclusions. 
Stratification is essential in environmental and field studies when the population can be partitioned into subgroups that may have different mean values. Though, stratified sampling can be more difficult and time-consuming.

---

# Part II — Sampling designs extensions (graded practice)

In Part I you treated the full 2023 half-hourly record as a **population**, then compared **simple random sampling** (SRS) vs **stratified sampling by month**.

Now you will practice additional **sampling designs** discussed in lecture:

- **Systematic** sampling (regular interval)
- **Cluster** sampling (sample groups, then measure everything in them)
- **Quasi-continuous** sampling (regular time series subsampling)
- **Blocked** designs (preview only — think “blocks as structure”)

All exercises below should run using the same objects from Part I:
- `df` (with `date`, `month`, `day_night`)
- `response_var`
- `pop_mean`, `pop_sd`
- your SRS sample `samp` and stratified sample `samp_strat` (if you created them)

> **Tip:** If you renamed objects in Part I, update the code below to match your names.

---

## Exercise 1 — Systematic sampling (every k-th observation)

**Idea:** sample at a fixed interval (e.g., every 48th record ≈ daily at 30-min resolution).

**Risk:** if the variable has strong cycles aligned with the interval, systematic sampling can be biased.

```{r systematic_sampling, echo=TRUE, eval=FALSE}
# GOAL: Create a systematic sample and compare mean/sd to population.
# TODO: choose an interval k (try 48, 24, 96).
k <- ___

sys_samp <- df %>%
  # TODO: keep only non-missing response values
  filter(!is.na(.data[[response_var]])) %>%
  slice(seq(1, n(), by = k))

sys_mean <- mean(sys_samp[[response_var]], na.rm = TRUE)
sys_sd   <- sd(sys_samp[[response_var]], na.rm = TRUE)

tibble(
  strategy = c("Population", "Systematic"),
  mean = c(pop_mean, sys_mean),
  sd   = c(pop_sd,   sys_sd),
  n    = c(nrow(df), nrow(sys_samp))
)
```

**Prompt (3–4 sentences):** Did systematic sampling approximate the population mean/SD better or worse than SRS?  
What cycle (daily or seasonal) might be interacting with your chosen `k`?

> *Write your answer here.*

---

## Exercise 2 — Cluster sampling (sample days, take all points within those days)

**Definition:** choose a set of clusters (here, **days**) at random, then include **all observations** in the chosen clusters.

This mimics EAES logistics: you may only be able to sample on certain days.

```{r cluster_sampling_days, echo=TRUE, eval=FALSE}
# GOAL: Sample whole days as clusters, then estimate mean/sd.
# TODO: choose number of days to sample.
set.seed(480)

n_days <- ___

days <- df %>%
  distinct(date) %>%
  drop_na(date) %>%
  pull(date)

chosen_days <- sample(days, size = n_days, replace = FALSE)

cluster_samp <- df %>%
  filter(date %in% chosen_days) %>%
  filter(!is.na(.data[[response_var]]))

clust_mean <- mean(cluster_samp[[response_var]], na.rm = TRUE)
clust_sd   <- sd(cluster_samp[[response_var]], na.rm = TRUE)

tibble(
  strategy = c("Population", "Cluster (days)"),
  mean = c(pop_mean, clust_mean),
  sd   = c(pop_sd,   clust_sd),
  n    = c(nrow(df), nrow(cluster_samp))
)
```

**Prompt (3–4 sentences):** Why might cluster sampling have **higher variance** than SRS for the same number of measurements?  
What feature of time series data (hint: autocorrelation) is relevant here?

> *Write your answer here.*

---

## Exercise 3 — Quasi-continuous sampling (fixed schedule time series)

**Definition:** sample regularly over time to create a *subsampled time series*.

This mimics continuous instrumentation that logs at a lower frequency (e.g., hourly instead of 30-min).

```{r quasi_continuous, echo=TRUE, eval=FALSE}
# GOAL: Create a regular subsampled time series.
# TODO: choose a step size (every 2 records = hourly; every 4 = 2-hourly).
step <- ___

qc_samp <- df %>%
  filter(!is.na(.data[[response_var]])) %>%
  slice(seq(1, n(), by = step))

qc_mean <- mean(qc_samp[[response_var]], na.rm = TRUE)
qc_sd   <- sd(qc_samp[[response_var]], na.rm = TRUE)

tibble(
  strategy = c("Population", "Quasi-continuous"),
  mean = c(pop_mean, qc_mean),
  sd   = c(pop_sd,   qc_sd),
  n    = c(nrow(df), nrow(qc_samp))
)
```

### Visual check: does the subsampled series preserve structure?

```{r qc_plot, echo=TRUE, eval=FALSE}
# TODO: plot BOTH population and qc_samp time series (thin lines) for a short window
# HINT: filter to one month to avoid overplotting.

df %>%
  filter(month == ___) %>%   # e.g., "Jul" if month is labeled
  ggplot(aes(x = date, y = .data[[response_var]])) +
  geom_line(alpha = 0.25) +
  theme_classic(base_size = 18) +
  labs(title = "Population time series (subset)", x = NULL, y = response_var)

qc_samp %>%
  filter(month == ___) %>%
  ggplot(aes(x = date, y = .data[[response_var]])) +
  geom_line(alpha = 0.6) +
  theme_classic(base_size = 18) +
  labs(title = "Quasi-continuous sample time series (subset)", x = NULL, y = response_var)
```

**Prompt (3–4 sentences):** Does quasi-continuous sampling preserve the **seasonal** pattern? The **daily** pattern?  
In an EAES context, when is quasi-continuous sampling preferable to sparse discrete sampling?

> *Write your answer here.*

---

## Exercise 4 — Compare all strategies in one table (and interpret)

```{r compare_all, echo=TRUE, eval=FALSE}
# GOAL: Assemble a comparison table of mean/sd error for each strategy.
# NOTE: This assumes you created objects: samp, samp_strat, sys_samp, cluster_samp, qc_samp.
# If your object names differ, update them here.

summ_stats <- function(dat, label) {
  tibble(
    strategy = label,
    n = nrow(dat),
    mean = mean(dat[[response_var]], na.rm = TRUE),
    sd   = sd(dat[[response_var]], na.rm = TRUE)
  )
}

bind_rows(
  tibble(strategy = "Population", n = nrow(df), mean = pop_mean, sd = pop_sd),
  summ_stats(samp, "SRS"),
  summ_stats(samp_strat, "Stratified (month)"),
  summ_stats(sys_samp, "Systematic"),
  summ_stats(cluster_samp, "Cluster (days)"),
  summ_stats(qc_samp, "Quasi-continuous")
) %>%
  mutate(
    mean_error = mean - pop_mean,
    sd_error   = sd - pop_sd
  )
```

**Prompt (5–6 sentences, graded):** Which strategy gave the best estimate of the population mean? Of the population SD?  
Explain *why* in terms of (i) seasonal/diurnal structure and (ii) dependence/autocorrelation.  
If you were designing a real EAES study with limited field days, what hybrid strategy would you propose (e.g., stratified + clustered)?

> *Write your answer here.*

---

## Blocked designs (preview only — do not implement yet)

A **blocked** design means sampling within blocks (time blocks like months, or spatial blocks like sites), then later treating block as structure in the model (often as a random effect).

You already approximated blocking by stratifying over `month`. Later, we will return to this idea when we fit models that include block structure explicitly.

# Submission + self-check

## Before you knit (Run All)
- [ ] Setup chunk runs without errors
- [ ] Data join happened (df_raw has both canopy + climate columns)
- [ ] All chunks run top-to-bottom
- [ ] No objects created only in the Console
- [ ] Interpretation answers are complete sentences

## After you knit
- [ ] Figures appear in the output
- [ ] Tables render and are readable
- [ ] Your selected x and y are clearly stated in the document

**Save, commit, push to Github.**
